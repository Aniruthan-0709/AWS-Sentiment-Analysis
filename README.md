Certainly! Below is your complete `README.md` with the **step-by-step textual pipeline flowchart** seamlessly added **after the Visual Overview** section. This preserves your existing structure and enhances clarity by detailing the entire pipeline lifecycle.

---

```markdown
# ğŸ§  AWS Sentiment Analysis Pipeline

This repository implements an end-to-end sentiment analysis pipeline using AWS services with fully automated CI/CD using GitHub Actions. It handles data ingestion, preprocessing, model training, evaluation, and deployment with a web-based user interface.

---

## ğŸ“ Project Structure

```

sentiment-app/
â”œâ”€â”€ backend/                # FastAPI backend APIs
â”‚   â”œâ”€â”€ main.py             # Entry point for FastAPI
â”‚   â”œâ”€â”€ routes/             # API endpoints
â”‚   â””â”€â”€ utils/              # Utility functions
â”œâ”€â”€ frontend/               # Streamlit user interface
â”‚   â””â”€â”€ streamlit\_app.py    # Frontend application
â”œâ”€â”€ sentiment-pipeline/     # PySpark + BERT inference logic
â”‚   â”œâ”€â”€ run\_clean.py        # Preprocessing
â”‚   â”œâ”€â”€ run\_infer.py        # Inference
â”‚   â””â”€â”€ run\_all.py          # Combined pipeline for ECS
â”œâ”€â”€ Dockerfile              # Containerization for Spark + Transformers
â”œâ”€â”€ requirements.txt        # Unified Python dependencies
â””â”€â”€ .github/workflows/      # GitHub Actions CI/CD workflows

````

---

## ğŸ”„ Data Pipeline (AWS Glue)

| Step              | Script                  | Input                             | Output                                  |
| ----------------- | ----------------------- | --------------------------------- | --------------------------------------- |
| Preprocessing     | `data_preprocessing.py` | `Bronze/train.parquet`            | `Bronze/pre_processed.parquet`          |
| Schema Validation | `schema_validation.py`  | `Bronze/pre_processed.parquet`    | `Bronze/schema_validated.parquet`       |
| Anomaly Detection | `anomaly_detection.py`  | `Bronze/schema_validated.parquet` | `Bronze/anomaly_flagged.parquet`        |
| Sampling          | `sampling.py`           | `Bronze/anomaly_flagged.parquet`  | `Silver/sampled.csv`, `Silver/test.csv` |

**Orchestrated via**: AWS Glue Workflows

---

## ğŸ¤— Model Training & Evaluation (SageMaker)

* **Model**: DistilBERT  
* **Training**: AWS SageMaker (`Silver/sampled.csv`)  
* **Evaluation**: Local using Hugging Face `Trainer.evaluate()` on `Silver/test.csv`

**Metrics**:
- Accuracy: 93.14%
- Precision: 94.34%
- Recall: 91.78%
- F1 Score: 93.05%

**Artifacts**:  
`s3://mlops-sentiment-analysis-data/models/model.tar.gz`

---

## ğŸš€ Deployment

### ğŸ–¥ï¸ Backend (FastAPI)

* `/login` - AWS Cognito  
* `/trigger_pipeline` - Launch ECS job  
* `/generate_dashboard` - Generate dashboard  

### ğŸŒ Frontend (Streamlit)

* Upload CSV â†’ Trigger pipeline â†’ View dashboard  
* Polls ECS job status in real-time  

### ğŸ³ ECS Fargate Execution

* `run_all.py`: Executes preprocessing and inference using Spark and Transformers  
* Output saved to S3:  
  - `processed/{user}/processed.csv`  
  - `output/{user}/served.csv`  

---

## ğŸ” CI/CD (GitHub Actions)

### âœ… Continuous Integration (CI)

* Run on every push  
* Installs dependencies  
* Executes unit tests with `pytest`  

### ğŸš€ Continuous Deployment (CD)

* Builds Docker image  
* Pushes to AWS ECR  
* Deploys updated image to ECS task  
* Triggers SageMaker training and logs output to MLflow  

---

## ğŸ” Environment Setup

* `.env` file includes credentials for Cognito, ECS, and S3  
* Transferred securely via SCP to EC2 instance  

```bash
scp -i "key.pem" .env ec2-user@<ec2-ip>:/home/ec2-user/sentiment-app/backend/
````

---

## ğŸ“Š Visual Overview

### ğŸ”¸ Data + Model + Deployment Pipeline

```mermaid
flowchart TD
    A[Upload CSV via Streamlit] --> B[FastAPI Trigger]
    B --> C[ECS Fargate: run_all.py]
    C --> D[S3: processed.csv + served.csv]
    D --> E[FastAPI: generate_dashboard]
    E --> F[Streamlit: Display Results]
```

---

## ğŸ§© End-to-End Pipeline Overview

This project consists of four major stages: **Data Pipeline (Glue)**, **Model Training (SageMaker)**, **Application Inference (ECS + UI)**, and **CI/CD Automation (GitHub Actions)**.

---

### ğŸ” 1. Data Pipeline â€” *AWS Glue + S3*

Orchestrated by AWS Glue Workflows.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         AWS Glue Workflow            â”‚
â”‚  â”œâ”€ data_preprocessing.py            â”‚
â”‚  â”‚   - Drop nulls, clean text        â”‚
â”‚  â”œâ”€ schema_validation.py             â”‚
â”‚  â”‚   - Validate text/rating          â”‚
â”‚  â”œâ”€ anomaly_detection.py             â”‚
â”‚  â”‚   - Flag short/long reviews       â”‚
â”‚  â””â”€ sampling.py                      â”‚
â”‚      - Remove neutral, stratify      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Amazon S3                     â”‚
â”‚ â”œâ”€ raw/                  â† raw reviews.csv    â”‚
â”‚ â”œâ”€ Bronze/               â† cleaned .parquet   â”‚
â”‚ â”œâ”€ Silver/               â† sampled.csv, test  â”‚
â”‚ â””â”€ metadata/             â† class dist, length â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### ğŸ§  2. Model Training â€” *Amazon SageMaker + Hugging Face*

Fine-tune DistilBERT on preprocessed and labeled data.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Amazon SageMaker Training          â”‚
â”‚  - Input: Silver/sampled.csv                 â”‚
â”‚  - Model: DistilBERT (transformers)          â”‚
â”‚  - Output: model.tar.gz â†’ S3/models/         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Evaluation (local or CI/CD)            â”‚
â”‚  - Input: Silver/test.csv                    â”‚
â”‚  - Logs: Accuracy, Precision, Recall, F1     â”‚
â”‚  - Save: tested.csv + model_evaluation.json  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### ğŸ’» 3. Application Inference â€” *User + ECS + FastAPI + Streamlit*

Triggered directly by the user via the Streamlit frontend.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            User (via UI)          â”‚
â”‚ Uploads CSV to Streamlit App      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Streamlit Frontend         â”‚
â”‚ - Upload CSV                      â”‚
â”‚ - Triggers FastAPI endpoint       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        FastAPI Backend             â”‚
â”‚ - /trigger_pipeline: ECS run_all   â”‚
â”‚ - /generate_dashboard: summarize   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ECS Fargate Task           â”‚
â”‚ - run_all.py = run_clean + infer   â”‚
â”‚ - Loads model.tar.gz               â”‚
â”‚ - Writes to output/{user}/served.csv â”‚
â”‚ - Updates inference_summary.json   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Streamlit shows dashboard      â”‚
â”‚ - Top reviews, sentiment dist.     â”‚
â”‚ - Real-time polling from S3        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### ğŸ” 4. CI/CD â€” *GitHub Actions + ECR + ECS + SageMaker*

Fully automated deployment and model training pipeline.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         GitHub Actions CI/CD          â”‚
â”‚ - On push / PR                        â”‚
â”‚   â”œâ”€ Install + test (pytest)          â”‚
â”‚   â”œâ”€ Build Docker (Spark+BERT image)  â”‚
â”‚   â”œâ”€ Push to Amazon ECR               â”‚
â”‚   â”œâ”€ Update ECS Task (Fargate)        â”‚
â”‚   â””â”€ Trigger SageMaker Training Job   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### âœ… Summary Table

| Stage         | Services Used                               |
| ------------- | ------------------------------------------- |
| Data Pipeline | AWS Glue, AWS S3                            |
| Model Train   | Amazon SageMaker, Hugging Face Transformers |
| Inference App | ECS Fargate, FastAPI, Streamlit, S3         |
| CI/CD         | GitHub Actions, Amazon ECR, ECS, SageMaker  |

---

## ğŸ“ S3 Bucket Structure

```
s3://mlops-sentiment-analysis-data/
â”œâ”€â”€ raw/
â”œâ”€â”€ Bronze/
â”œâ”€â”€ Silver/
â”œâ”€â”€ test/
â”œâ”€â”€ output/{user}/served.csv
â”œâ”€â”€ processed/{user}/processed.csv
â”œâ”€â”€ metadata/
```

---

## ğŸ“¡ Monitoring & Logs

```bash
# Backend logs
$ tail -f fastapi.log

# Frontend logs
$ tail -f streamlit.log
```

---

## ğŸ™Œ Credits

Built using: AWS Glue, SageMaker, ECS Fargate, EC2, FastAPI, Streamlit, HuggingFace, PySpark, MLflow

---

> âœ¨ Fully CI/CD-enabled, cloud-optimized sentiment analysis app ready for production!
